[
  {
    "objectID": "Childcare Costs.html",
    "href": "Childcare Costs.html",
    "title": "Childcare Costs",
    "section": "",
    "text": "This dataset comes from the National Database of Childcare Prices (NDCP), which is (one of) the most comprehensive federal source of childcare at the county level. Data provided by Thomas Mock.\n\nlibrary(tidyverse)\n\nchildcare_costs &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2023/2023-05-09/childcare_costs.csv')\n\nchildcare_costs |&gt;\nggplot( aes( x = mcsa, y = pr_f ) ) +\n  geom_point(color = \"blue\", alpha = 0.1) +\n  labs( x = \"median price charged for center-based care who are school age\",\n        y = \"poverty rate for familie\" )\n\n\n\n\n\n\n\n\nData taken from TidyTuesday GitHub Repository: https://github.com/rfordatascience/tidytuesday/tree/main/data\nData originally sourced from National Database of Childcare Prices:\nhttps://www.dol.gov/agencies/wb/topics/featured-childcare"
  },
  {
    "objectID": "The Scent of Data.html",
    "href": "The Scent of Data.html",
    "title": "The Scent of Data",
    "section": "",
    "text": "This dataset contains information about perfumes webscraped from Parfumo (community of perfume enthusiasts) by Olga G..\n\nlibrary(dplyr)\nlibrary(tidyverse)\n\nparfumo_data_clean &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2024/2024-12-10/parfumo_data_clean.csv')\n\nbrand_vs_rating &lt;- parfumo_data_clean |&gt;\n  group_by(Brand) |&gt;\n  summarize( Average_Rating_Value = mean(Rating_Value, na.rm = TRUE) ) |&gt;\n  arrange( desc( Average_Rating_Value ) ) \n\ntop10_brand_vs_rating &lt;- head( brand_vs_rating, 10)\n  \nggplot( top10_brand_vs_rating, aes( x = Brand, y = Average_Rating_Value, fill = Brand ) ) +\n  geom_bar( stat = \"identity\") +\n  theme(axis.text.x = element_blank())\n\n\n\n\n\n\n\n\nData taken from TidyTuesday GitHub Repository: https://github.com/rfordatascience/tidytuesday/tree/main/data\nData originally sourced from Perfumo:\nhttps://www.parfumo.com/"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Zhesheng(Jason) Xu",
    "section": "",
    "text": "Hi there! I’m Jason, my hometown is Shanghai, China! I am currently a student at Pomona College, CA, where I am studying neuroscience and data science. I am also a part of a club called Health Bridges where I get to volunteer at Pomona Valley Hospital as a non-medical translator! In my free time, I like to play the guitar (Chinese folk songs are my favorite!). Look around my website to learn more!\nI used Quarto to build this website, the link to the repository is here: https://github.com/ASTROXXXXX/ASTROXXXXX.github.io"
  },
  {
    "objectID": "Strings.html",
    "href": "Strings.html",
    "title": "Macbeth",
    "section": "",
    "text": "This dataset contains the entire script of the famous Shakesqeare play: Macbeth. As a side note, I was actually really into acting back in middle school, and I actually played a character (who’s name I forgot - not a big character) in Macbeth during one of the school shows. I’m excited, let’s go ahead and play with the data :)\n\nlibrary(dplyr)\nlibrary(tidyverse)\n\nmacbeth &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2024/2024-09-17/macbeth.csv')\n\nneg_lines &lt;- macbeth |&gt;\n  mutate( blood = str_detect( dialogue, \"(?i)blood|(?i)murder[er]|(?i)death|(?i)kill\" ) ) |&gt;\n  filter( blood ) |&gt;\n  group_by( act ) |&gt;\n  summarize( average_negative_lines = n() ) \n\naverage_words &lt;- macbeth |&gt;\n  mutate( string_length = str_length( dialogue ) ) |&gt;\n  group_by( act ) |&gt;\n  summarize( average_words = mean( string_length ) ) \n\nnegative_words &lt;- left_join( neg_lines, average_words )\n\nggplot( negative_words, aes(x = average_words, y = average_negative_lines, label = act)) +\n  geom_point(color = \"blue\", size = 3) +  \n  geom_text(vjust = -1, size = 4) +       \n  labs(title = \"Average Words vs. Negative Lines in each act of Macbeth\",\n       x = \"Average Words per Act\",\n       y = \"Number of Lines with Negative Words\" ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nHere, I counted the number of lines in each act of Macbeth that contained one or more “negative words”, which I defined to be “blood”, “murder(er)”, “death” and “kill”. Then, it is paired up with the average number of words in each act (see figure above). I was interested in knowing if a particular act had more lines containing “negative words” than perhaps the characters spoke more on average (or less, there is some relationship is the point). However, just by eyeballing the above plot, it seems like there is no clear relationship between the two. (noticeably, however, Act III is a pretty extreme outlier, if we ignore it the plot actually shows a pretty down-wards trending relationship).\n\nmacbeth |&gt;\n  filter( character == \"Macbeth\" ) |&gt;\n  mutate( love_strings = str_extract( dialogue, \"(?&lt;=(?i)love ).+\") ) |&gt;\n  filter( !is.na(love_strings) ) |&gt;\n  select( character:love_strings, -line_number )\n\n# A tibble: 4 × 3\n  character dialogue                                             love_strings   \n  &lt;chr&gt;     &lt;chr&gt;                                                &lt;chr&gt;          \n1 Macbeth   Safe toward your love and honour.                    and honour.    \n2 Macbeth   Courage to make 's love kno wn?                      kno wn?        \n3 Macbeth   Grapples you to the heart and love of us,            of us,         \n4 Macbeth   To those that know me. Come, love and health to all; and health to …\n\n\nAfter looking at the negative, I decided to turn to the opposite — whether if Macbeth, the main character of the play, has explicity expressed “love” in the play, and to whom. So I used the lookaround function to spot instances of Macbeth saying the word “love” and the “love_strings” is whatever comes after “love”. Sadly, these instances only occured 4 times in the whole play and they seem to occur only in more generic settings (like toasting) — poor lady Macbeth :(\nData taken from TidyTuesday GitHub Repository: https://github.com/rfordatascience/tidytuesday/tree/main/data\nData originally sourced from:\nhttps://shakespeare.mit.edu/"
  },
  {
    "objectID": "Simulation Analysis.html",
    "href": "Simulation Analysis.html",
    "title": "Simulation!",
    "section": "",
    "text": "Assuming that there are four course registration periods over four years of a student’s time at Pomona College (there are actually 8), and course registration happens once per year. Suppose that (drawing from personal experience) the college’s algorithm is designed so that it categorizes registration times into:\n1. Early: 8 ~ 10am.\n2. Moderately Early: 10 ~ noon.\n3. Moderately Late: noon ~ 2pm.\n4. Late: 2 ~ 4pm.\nand suppose that during course registration the algorithm first randomly determines a category and than randomly assigns a time (by each minute) within that category to each student and also makes sure that each category is assigned to each student only once over their four years at the college (i.e four course registrations).\nSuppose that the best thing to happen is either A. a freshman gets a time before 9am (so that he/she can beat the other freshmen in the same category) B. a sophomore gets a time before 11am. I want to use simulation to find the probability of A., B. and for the luckiest ones, A. and B. both happen.\n\nlibrary(tidyverse)\nset.seed(47)\n\ncorsreg_func &lt;- function(banana){\n  # shuffle categories\n  cats = sample(c(1:4), 4, replace = FALSE)\n  # a random time in 2 hours\n  times = sample(c(1:120), 4, replace = TRUE)\n\n  data.frame(\n  lucky_freshman = (cats[1] == 1 && times[1] &lt;= 59),\n  lucky_sophomore = (cats[2] == 1 | cats[2] == 2 && times[2] &lt;= 59),\n  luckiest_one = ((cats[1] == 1 && times[1] &lt;= 59) && (cats[2] == 1 | cats[2] == 2 && times[2] &lt;= 59)))\n  }\n\nn &lt;- 1761\ncorsreg_data &lt;- map(1:n, corsreg_func) |&gt;\n  list_rbind()\n\nsummary_data &lt;- corsreg_data |&gt;\n  summarise(\n    lucky_freshman_prop = mean(lucky_freshman),\n    lucky_sophomore_prop = mean(lucky_sophomore),\n    luckiest_one_prop = mean(luckiest_one)\n  ) |&gt;\n  pivot_longer(cols = everything(), names_to = \"category\", values_to = \"proportion\")\n\n\nsummary_data$category &lt;- factor(summary_data$category, \n                                 levels = c(\"lucky_freshman_prop\", \"lucky_sophomore_prop\", \"luckiest_one_prop\"))\n\n\nggplot(summary_data, aes(x = category, y = proportion, fill = category)) +\n  geom_bar(stat = \"identity\", width = 0.6) +\n  labs(\n    title = \"Course Registration Simulation at Pomona College\",\n    x = \"I simulated 1761 times to approximate the number of students on campus\",\n    y = \"Proportion\"\n  ) +\n  theme_minimal() +\n  geom_text(aes(label = round(proportion, 3)), vjust = -0.5) +  \n  ylim(0, 1) +\n  theme(axis.text.x = element_blank())\n\n\n\n\n\n\n\n\nSeems like there is around 11% probability for a student to be lucky in their course registrations during their freshman year, and a much greater probability (around 36%) for him/her to be lucky in their sophomore year. But getting extremely lucky, where he/she get an early time for both years is extremely rare (around 2%). Despite the fact that I believe getting a time before 9am is pretty important for a freshman to get into a class they wanted, knowing that there is almost 40% students who will get an ideal time in their sophomore year is pretty relieving. Some lucky sophomores may also be lucky in their freshman year, but that rate is low (around 2%). I personally think that the algorithm, as presented here, seems to be decent, because we are getting ideal results for almost 40% of the students in their sophomore year (which is pretty high). But things could also be said about the pretty low rate (11%) to be lucky freshman. But it is also important to note that we have other mechanisms to distribute courses to students who actually need them (or need them more), such as the PERM system or considerations on individual basis."
  }
]